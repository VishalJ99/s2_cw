

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs} % For prettier tables
\usepackage{siunitx}
\usepackage{amssymb}
\usepackage{url}

% Set page margins
\geometry{a4paper, margin=1in}

% Set up code listing style
\lstset{
    basicstyle=\ttfamily,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    showstringspaces=false,
    captionpos=b
}

\title{The Lighthouse Problem: S2 coursework report}
\author{Vishal Jain}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
This coursework is based on the lighthouse problem. Where a lighthouse is at position \( \alpha \) along a straight coastline and a distance \( \beta \) out to sea. The lighthouse rotates and emits flashes at uniformly-distributed random angles \( \theta \); the light beams are narrow and if \( -\frac{\pi}{2} < \theta < \frac{\pi}{2} \), intersect the coastline at a single point. An array of detectors spread along the coastline record the locations \( x_k \) (where \( k = 1, 2, \ldots, N \)) where \( N \) flashes are received; the detectors only record that a flash has occurred, not the direction from which it was received. Your task is to find the location of the lighthouse. The setup is illustrated in Fig \ref{fig:setup}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{figs/set-up.png}
    \caption{The lighthouse problem setup}
    \label{fig:setup}
\end{figure}


\subsection{Part i - Trigonometric Relationship between Variables}

From basic trigonometry, the tangent of the angle \( \theta \), where \( \theta \) is the angle of the light beam with respect to a line perpendicular to the coastline, is defined as the ratio of the opposite side to the adjacent side of the right angled triangle formed by the points $(\alpha,\beta)$, $(x,0)$ and $(\alpha,0)$. This relationship can be represented as:
\[
\tan(\theta) = \frac{x-\alpha}{\beta}.
\]

\subsection{Part ii - Probability Density Function of \( x \)}


The probability density function $Pr(x)$, can be found from the following relationship:
\[
Pr(\theta)d\theta = Pr(x)dx
\]
Given that \( \theta \sim U(-\frac{\pi}{2}, \frac{\pi}{2}) \),
the probability density function of \( \theta \) is defined as:
\[
Pr(\theta) = \left\{
    \begin{array}{ll}
        \frac{1}{\pi} & \text{if } -\frac{\pi}{2} \leq \theta \leq \frac{\pi}{2} \\
        0 & \text{otherwise}
    \end{array}
\right.
\]
Therefore, in this interval, the probability density function of \( x \) is given by:
$$
Pr(x) = Pr(\theta)\frac{d\theta}{dx} 
$$
$$
= \frac{1}{\pi} \frac{d\theta}{dx}
$$
$$
= \frac{1}{\pi} \frac{d}{dx} \arctan \left( \frac{x-\alpha}{\beta} \right)
$$
\begin{equation}
\therefore Pr(x) = \frac{1}{\pi} \left( \frac{\beta}{\beta^2 + (x-\alpha)^2} \right)
\label{eq:pdf_x}
\end{equation}

Where the last line follows from the standard derivative formula for the arctan function:
\[
\frac{d}{dx} \arctan(x) = \frac{1}{1+x^2}
\]
Using this expression with the chain rule, the probability density function for \( x \) can be obtained.

\section{Finding the Lighthouse}
\subsection{Part iii - Most Likely Location of a Flash}
Given the previously calculated probability density function of \( x \), the distribution can be visualised for different light house locations. Figure \ref{fig:cauchy_distribution} shows the probability density function of \( x \) for 3 different choices of \( \alpha \) and \( \beta \). The plots reveal several interesting properties about the PDF of $x$. Firstly, as the value of $\beta$ decreases, the peak
becomes more pronounced. This makes sense as the closer the lighthouse to the shore, the fewer detectors its flashes could intersect with and thus the more information its flashes would give about its location along the shore. The plots also reveals that the peak of the distribution occurs at $x=\alpha$, this can also be seen by inspection of equation \ref{eq:pdf_x}. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/cauchy_distribution.png}
    \caption{Probability density function of \( x \) for 3 different choices of \( \alpha \) and \( \beta \)}
    \label{fig:cauchy_distribution}
\end{figure}

To estimate $\alpha$, one may consider using the sample mean of $x$, however, since $x$ follows a cauchy distribution, the sample mean will not converge as the distribution's mean and variance are both undefined. Another way to show that the sample mean is not a good estimator of $\alpha$ is to consider the maximum likelihood estimator of $\alpha$, which is a good estimator. The MLE estimate of $\alpha$ can be found by taking the derivative of the log likelihood function with respect to $\alpha$ and setting it to zero. The likelihood function of a set of flashes $\{x_k\}$ is given by:
\[
L(\{x_k\}|\alpha,\beta) = \prod_{k=1}^{N} Pr(x_k),
\] this follows by the independence of the flashes. The log likelihood function is then given by:
\[
\log L(\{x_k\}|\alpha,\beta) = \sum_{k=1}^{N} \log Pr(x_k).
\] Substituting in the expression for $Pr(x)$ from equation \ref{eq:pdf_x} gives:
\[
\log L(\{x_k\}|\alpha,\beta) = \sum_{k=1}^{N} \log \left( \frac{\beta}{\pi(\beta^2 + (x_k-\alpha)^2)} \right).
\]
Taking the derivative of this with respect to $\alpha$ and setting it to zero gives the expression:
\[
0 = \sum_{k=1}^{N} \frac{2(x_k-\hat\alpha)}{\beta^2 + (x_k - \hat\alpha)^2},
\] where $\hat\alpha$ is the MLE estimate of $\alpha$. Note how the MLE estimate of $\alpha$ does not reduce to the sample mean of $x$. This equation can be solved numerically to find the MLE estimate of $\alpha$.

\subsection{Part iv - Prior Distribution of $\alpha$ and $\beta$}

To build a posterior distribution for $\alpha$ and $\beta$, first their prior distributions must be defined. The choice of prior should capture the current state of belief regarding the values of $\alpha$ and $\beta$. As the lighthouse is equally likely to be at any location along the coast and at any distance from the coast, choosing a uniform prior distribution is a sensible approach. This is because a uniform prior distribution assigns equal probability to all values of $\alpha$ and $\beta$. 
\begin{equation}
Pr(\alpha, \beta) = \left\{
    \begin{array}{ll}
        \frac{1}{(a-b)(c-d)} & \text{if }  a \leq \alpha \leq b \text{ and } c \leq \beta \leq d  \\
        0 & \text{otherwise}
    \end{array}
\right.
\end{equation}

In theory the values for $a$, $b$, $c$ and $d$ should be determined in a manner which does not involve the data. However, in practice, to ensure the prior provides relevant support, the values of $a$, $b$, $c$ and $d$ are set by looking at the data and deciding on a conservative range. In this case, the values of $a$, $b$, $c$ and $d$ were set to be $-100$, $100$, $0$, $50$ respectively.


\subsection{Part v - Posterior Distribution of $\alpha$ and $\beta$}

The posterior $p(\alpha, \beta | \{x_k\})$ can be found using Bayes' theorem:
\[
p(\alpha, \beta | \{x_k\}) = \frac{p(\{x_k\} | \alpha, \beta) p(\alpha, \beta)}{p(\{x_k\})},
\] where $p(\{x_k\} | \alpha, \beta)$ is the likelihood function, $p(\alpha, \beta)$ is the prior distribution and $p(\{x_k\})$ is the bayesian evidence. 
% Explain MH algorithm.
To draw samples from the posterior distribution, we can use the Metropolis-Hastings algorithm \cite{Robert2004}. The Metropolis-Hastings algorithm is a Markov Chain Monte Carlo (MCMC)
method that generates a sequence of samples from a target distribution. The algorithm works by first proposing a distribution $Q$ and starting point $\mathbf{x_0}$. The proposal is selected to be a distribution which is easy to sample from. Points are drawn from this proposal distribution and accepted or rejected based on an acceptance ratio. The acceptance ratio is a function of the proposal distribution and the target distribution. In the current case, a 2 dimensional gaussian is used as the proposal to draw points $(\alpha, \beta)$.
% Explain pros and cons of MH algorithm
This sampling algorithm is simple and also convenient in that it works using only the ratios of the target distribution, so the evidence is not required. The algorithm is outlined in Algorithm \ref{alg:metropolis_hastings}.

\begin{algorithm}[H]
    \caption{Metropolis Hastings}
    \begin{algorithmic}[1]
    \State $x_0 \sim \alpha$
    \State $i \gets 0$
    \While{$i \geq 0$}
        \State $y \sim Q(y|x_i)$ \Comment{Proposal}
        \State $a \gets \left(\frac{P(y)Q(x_i|y)}{P(x_i)Q(y|x_i)}\right)$ \Comment{MH acceptance probability}
        \State $u \sim U(0,1)$
        \If{$u < a$}
            \State $x_{i+1} \gets y$ \Comment{Accept}
        \Else
            \State $x_{i+1} \gets x_i$ \Comment{Reject}
        \EndIf
        \State $i \gets i + 1$
    \EndWhile
    \end{algorithmic}
    \label{alg:metropolis_hastings}
\end{algorithm}
    
Note that the expression for the acceptance ratio $a$ simplifies to the ratio of the target distribution $\frac{P(y)}{P(x_i)}$ when the proposal distribution is symmetric, as is the case in the current situation. This is a key feature of the Metropolis-Hastings algorithm with symmetric proposal distributions. It is assumed that there is no correlation between the parameters $\alpha$ and $\beta$. As such the covariance matrix for the 2D gaussian proposal distribution is diagonal. 

Since consecutive points in the chain are generated sequentially from the previous point, they are not independent. To go from the samples returned by the Metropolis-Hastings algorithm to independent samples, there are 2 corrections that are made to the chain. Specifically, the 'burn-in' period must be discarded and the samples must be thinned. 
The burn-in period is the number of samples that are discarded at the start of the chain before it converges towards the target distribution. Discarding the burn in ensures that the distribution of the final set of samples are not influenced by any transient behaviour induced by the choice of initial values. The burn in is normally determined manually be inspecting the trace plots. The trace plot is just the name given to the plot of the random variable / parameter values (in this case $\alpha$ and $\beta$) at each step of the chain.
The thinning factor is the number of samples that are skipped to reduce the correlation between samples. To determine the number of samples to skip, the integrated autocorrelation time (IAT) is calculated. 
\subsubsection{Aside: Emcee integrated autocorrelation time}
To compute IAT, the \texttt{emcee} package was used. The package deviates slightly from the typical estimator for the IAT. \cite{emcee}. This section gives a brief overview of the difference.  The IAT is defined as:
\begin{equation}
\tau_f = \sum_{\tau=-\infty}^{\infty} \rho_f(\tau)
\end{equation}
where  \(\tau_f\) is the IAT, \(\tau\) is the lag, which is the distance between elements of the chain, \(\rho_f(\tau)\) is the normalised autocorrelation as a function of \(\tau\). For a finite chain, you can estimate \(\rho_f(\tau)\) as
\begin{equation}
\hat{\rho}_f(\tau) = \frac{\hat{c}_f(\tau)}{\hat{c}_f(0)}
\end{equation}
where
\begin{equation}
\hat{c}_f(\tau) = \frac{1}{N - \tau} \sum_{n=1}^{N-\tau} (f_n - \mu_f) (f_{n+\tau} - \mu_f)
\end{equation}
and
\begin{equation}
\mu_f = \frac{1}{N} \sum_{n=1}^{N} f_n.
\end{equation}
Here \(N\) is the length of the chain and \(f_n\) is the value of the chain at the \(n\)th step and \(\mu_f\) is the sample mean of the chain. The integrated autocorrelation time \(\tau_f\) can now be estimated as:

\begin{equation}
\hat{\tau}_f = \sum_{\tau=-(N-1)}^{N-1} \hat{\rho}_f(\tau) = 1 + 2 \sum_{\tau=1}^{N-1} \hat{\rho}_f(\tau)
\end{equation}
However, the \texttt{emcee} package uses the following estimator for \(\tau_f\). 
\begin{equation}
\hat{\tau}_f(M) = 1 + 2 \sum_{\tau=1}^{M} \hat{\rho}_f(\tau)
\end{equation}
For some \(M \ll N\). Where satisfies \(M \ge C \hat{\tau}_f(M)\) for a constant \(C \approx 5\). This approach decreases the variance of the estimator at the cost of bias.

% Show param tuning of MH algorithm - justify 0 correlation between alpha and beta,
\subsubsection{Tuning the proposal distribution}
Before drawing samples using the Metropolis algorithm, the proposal distribution must be tuned. Tuning refers to finding the right values to initialise the gaussian proposal's covariance matrix. This ensures that consecutive elements in the chain have a low correlation. Note, the same variance was used for both parameters $\alpha$ and $\beta$ to reduce the search space. The method to tune the proposal distribution was as follows:

\begin{enumerate}
    \item Selecti a range of variances.
    \item Run an MCMC chain for each variance from a starting point that has a small burn-in.
    \item Calculate the integrated autocorrelation time (IAT) for each chain.
    \item Choose the maximum IAT between the parameters as the IAT for that variance.
    \item Identify the variance with the lowest IAT.
\end{enumerate}
This approach determined that the optimal variance for the proposal distribution to be 1. Figure \ref{fig:std_tuning} shows the IAT for different variances. Additionally, figure \ref{fig:std_tuning} also shows the acceptance rate for each variance. However, it is important to note that the acceptance rate does not contribute additional information into selecting the optimal variance. This is because the Metropolis Hastings algorithm  retains rejected points in the chain. The acceptance rate is shown for completeness and indicates how a large variance can lead to a low acceptance rate. It also explains why the IAT is high for large variances, since most points are rejected, there is a high auto correlation between elements of the chain.



% Plot of auto corr vs std size and efficiency vs std size
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/autocorrelation_time_vs_var.png}
    \caption{Acceptance rate and integrated autocorrelation time for different variances of the gaussian proposal distribution.}
    \label{fig:std_tuning}
\end{figure}

% Show joint hist, marginals and mean +- std of alpha and beta
\subsubsection{Sampling the posterior distribution}
To sample from the posterior, 10 chains were run for 100000 steps each. The burn in period was set to 10000, which is a very conservative estimate according to the trace plots shown in figures \ref{fig:trace_plots_alpha_1} and \ref{fig:trace_plots_beta_1}. The thinning factor was set to twice the maximum auto correlation length between alpha and beta for each chain after discarding the burn-in. The samples were then plotted as a joint histogram as shown in figure \ref{fig:joint_hist_1}. The marginal histograms are shown in figure \ref{fig:marginal_hist} and the mean and standard deviation of the samples are shown in table \ref{tab:mean_std}. It is worth noting that the mean and standard deviation are sample estimates, and as such have associated standard errors. These have been omitted as the standard error scales with $1/\sqrt{N}$ where N is the number of i.i.d samples. In this case, the number of i.i.d samples is large enough that the standard error is negligible.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/joint_hist_1.png}
    \caption{Joint distribution of samples of $\alpha$ and $\beta$}
    \label{fig:joint_hist_1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/marginals_1.png}
    \caption{Marginal histograms of samples from the posterior of $\alpha$ and $\beta$. Solid red line indicates the mean of the distribution, dashed red lines indicate the mean $\pm$ standard deviation.}
    \label{fig:marginal_hist}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Parameter & Mean & Standard Deviation \\ \midrule
    $\alpha$  & -0.449 & 0.6028 \\
    $\beta$   & 1.969 & 0.6673 \\ \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of samples of $\alpha$ and $\beta$}
    \label{tab:mean_std}
\end{table}

\subsubsection{Convergence diagnostics}
To ensure that the chains have converged, the trace plots of the chains shown in figures \ref{fig:trace_plots_alpha_1} and \ref{fig:trace_plots_beta_1} were inspected. The plots show that after the burn in period, the chains are well mixed and do not show any non stationary behaviour. These are signs of convergence. Another criteria used to assess the convergence was the Gelman Rubin statistic which compares the variance within each chain to the variance across the chains \cite{GelmanRubin1992}. The idea is that if all chains are converging to the same distribution, the within-chain variance should be similar to the between-chain variance. The statistics were calculated to be 1.0003 and 1.0001 for $\alpha$ and $\beta$ respectively. The closer the statistic is to 1, the more likely the chains have converged, a common threshold is 1.1.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_alpha_1.png}
    \caption{Trace plots of samples of $\alpha$}
    \label{fig:trace_plots_alpha_1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_beta_1.png}
    \caption{Trace plots of samples of $\beta$}
    \label{fig:trace_plots_beta_1}
\end{figure}
\section{Introducing Intensity - $I$}
The analysis is repeated now using the additional intensity measurements $I_k$ for $k = 1, 2, \ldots, N$ collected by the detectors. Intensity measurements are assumed to be independant and follow a log-normal distribution with an variance $\sigma^2$ of 1. The likelihood function for a single flashes intensity is given by:
\begin{equation}
    L(I|\alpha,\beta, I_0, x) = \frac{1}{I\sqrt{2\pi}} \exp\left(-\frac{1}{2} \left( \log(I) - \mu\right)^2 \right),
    \label{eq:likelihood_intensity}
\end{equation}
where the mean of the distribution $\mu = \log(I_0) - 2\log{\left(\beta^2+(x-\alpha^2)\right)}$.

\subsection{Part vi - Prior Distribution of $I_0$}
The log uniform distribution was chosen as the prior distribution for the new parameter $I_0$. This is because it respects the scale invariant property of the parameter. It assigns equal probability to all orders of magnitude of $I_0$. The log-uniform prior is defined as:

\begin{equation}
    Pr(I_0) = \left\{
        \begin{array}{ll}
            \frac{1}{I_0(\log(b/a))} & \text{if } a \leq I_0 \leq b \\
            0 & \text{otherwise}
        \end{array}
    \right.
\end{equation}

\subsubsection{Aside: Scale Invariance of The Log-Uniform Prior}
A distribution $Pr(x)$ is said to be scale invariant if it satisfies the following condition:
$$
Pr(x)dx = Pr(\alpha x) d(\alpha x),
$$ where $\alpha$ is some positive constant. This is equivalent to saying:
$$
\frac{Pr(x)}{Pr(\alpha x)} = \alpha
$$
If $Pr(x)$ is a log-uniform distribution, then:
$$
Pr(x) = \frac{1}{x(\log(b/a))}
$$
$$
Pr(\alpha x) = \frac{1}{\alpha x(\log(b/a))}
$$
$$
\frac{Pr(x)}{Pr(\alpha x)} = \frac{\alpha x(\log(b/a))}{x(\log(b/a))} = \alpha
$$
Therefore, the log-uniform distribution is scale invariant.

\subsection{Posterior Distribution of $\alpha$, $\beta$ and $I_0$}

 The posterior distribution of $\alpha$, $\beta$ and $I_0$ can be found using Bayes' theorem:
\begin{equation}
    Pr(\alpha, \beta, I_0 | \{x_k, I_k\}) = \frac{Pr(\{x_k, I_k\} | \alpha, \beta, I_0) Pr(\alpha, \beta, I_0)}{Pr(\{x_k, I_k\})},
\end{equation}
Assuming the parameters and measurements are independant, the priors and likelihoods can be factorised to give the following expression for the posterior:
$$
Pr(\alpha, \beta, I_0 | \{x_k, I_k\}) = \frac{Pr(\{I_k\} | \alpha, \beta, I_0,\{x_k\})Pr(\{x_k\} | \alpha, \beta)  Pr(\alpha, \beta)Pr(I_0)}{Pr(\{x_k\})Pr(\{I_k\})},
$$


\subsection{Tuning the proposal distribution}
Before drawing samples from the posterior, the covariance matrix for the proposal distribution was tuned. It was found through some experimentation that the IAT was most sensitive to the variance of the $\beta$ and $I_0$ parameters. These were swept over using a single chain with 20000 elements which started at the point $x_0 = (0, 1, 1)$. The results are shown in figure \ref{fig:std_tuning_2}. While the optimal variance was found to be 1 for $\alpha$, 0.1 for $\beta$ and 5 for $I_0$. In practice the variance for $\beta$ was set to 0.5. This was found to give the lowest IATs on average.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/IAT_heatmap.png}
    \caption{Integrated autocorrelation time for different $\beta$ and $I_0$ variances of the proposal distribution}
    \label{fig:std_tuning_2}
\end{figure}
\subsection{Part vii - Drawing Samples from the Posterior of $\alpha$, $\beta$ and $I_0$}
To draw samples from the posterior, 10 chains were run with taking 100000 steps each. The burn in period for each chain was set to 10000 and the thinning factor was set to twice the maximum IAT between $\alpha$, $\beta$ and $I_0$ for each chain. The samples were then used to generate the corner plot shown in figure \ref{fig:corner_plot}. The mean and standard deviation of the marginal distributions for each parameter are shown in table \ref{tab:mean_std_2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/corner_plot_2.png}
    \caption{Corner plot of samples $\alpha$, $\beta$ and $I_0$ from the posterior distribution.}
    \label{fig:corner_plot}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Parameter & Mean & Standard Deviation \\ \midrule
    $\alpha$  & -0.201 & 0.3290 \\
    $\beta$   & 1.513 & 0.3646 \\
    $I_0$    & 3.749 & 1.232 \\ \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of the parameter's $\alpha$, $\beta$ and $I_0$ marginal distributions.}
    \label{tab:mean_std_2}
\end{table}
\subsubsection{Convergence Diagnostics}
To ensure that the chains have converged, the trace plots of the chains shown in figures \ref{fig:trace_plots_alpha_2}, \ref{fig:trace_plots_beta_2} and \ref{fig:trace_plots_I0} were inspected. The plots show that after the burn in period, the chains are well mixed and do not show any non stationary behaviour. These are signs of convergence. Further, the Gelman Rubin statistic was calculated to be 1.003, 1.001 and 1.001 for $\alpha$, $\beta$ and $I_0$ respectively, providing more evidence that the chains have suitably converged.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_alpha_2.png}
    \caption{Trace plots of samples of $\alpha$}
    \label{fig:trace_plots_alpha_2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_beta_2.png}
    \caption{Trace plots of samples of $\beta$}
    \label{fig:trace_plots_beta_2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_I0.png}
    \caption{Trace plots of samples of $I_0$}
    \label{fig:trace_plots_I0}
\end{figure}

\section{Part viii - Comparison}
The new set of results shown in table \ref{tab:mean_std_2} for $\alpha$ shows a mean value of -0.201 which is similar to the previous set of results in table \ref{tab:mean_std} in which the mean value for $\alpha$ was -0.449. However, the standard deviation of the marginal distribution of $\alpha$ has decreased significantly from 0.6028 to 0.3290, indicating including the intensity data has lead to an improved measurement of $\alpha$.


\bibliographystyle{plainnat} % or another style depending on your requirements
\bibliography{ref.bib} % the name of your .bib file

% % Think about the best 
% \end{document}

\end{document}