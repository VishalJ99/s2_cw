

\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{float}
\usepackage{subcaption}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs} % For prettier tables
\usepackage{siunitx}
\usepackage{amssymb}
% Set page margins
\geometry{a4paper, margin=1in}

% Set up code listing style
\lstset{
    basicstyle=\ttfamily,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
    stringstyle=\color{red},
    showstringspaces=false,
    captionpos=b
}

\title{The Lighthouse Problem: S2 coursework report}
\author{Vishal Jain}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\newpage

\section{Introduction}
This coursework is based on the Lighthouse problem. Where a lighthouse is at position \( \alpha \) along a straight coastline and a distance \( \beta \) out to sea. The lighthouse rotates and emits flashes at uniformly-distributed random angles \( \theta \); the light beams are narrow and (if \( -\frac{\pi}{2} < \theta < \frac{\pi}{2} \)) intersect the coastline at a single point. An array of detectors spread along the coastline record the locations \( x_k \) (where \( k = 1, 2, \ldots, N \)) where \( N \) flashes are received; the detectors only record that a flash has occurred, not the direction from which it was received. Your task is to find the location of the lighthouse. The setup is illustrated in Fig \ref{fig:setup}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{figs/set-up.png}
    \caption{The lighthouse problem setup}
    \label{fig:setup}
\end{figure}


\subsection{Part i - Trigonometric relationship between variables}

From basic trigonometry, the tangent of the angle \( \theta \), where \( \theta \) is the angle of the light beam with respect to a line perpendicular to the coastline, is defined as the ratio of the opposite side to the adjacent side of the right angled triangle formed by the points $(\alpha,\beta)$, $(x,0)$ and $(\alpha,0)$. This relationship can be represented as:
\[
\tan(\theta) = \frac{x-\alpha}{\beta}.
\]

\subsection{Part ii - Probability density function of \( x \)}


the probability density function of \( x \) can be found from the following relationship:
\[
Pr(\theta)d\theta = Pr(x)dx
\]
Given that \( \theta \sim U(-\frac{\pi}{2}, \frac{\pi}{2}) \),
The probability density function of \( \theta \) is defined as:
\[
Pr(\theta) = \left\{
    \begin{array}{ll}
        \frac{1}{\pi} & \text{if } -\frac{\pi}{2} \leq \theta \leq \frac{\pi}{2} \\
        0 & \text{otherwise}
    \end{array}
\right.
\]
Therefore, in this interval, the probability density function of \( x \) is given by:
$$
Pr(x) = Pr(\theta)\frac{d\theta}{dx} 
$$
$$
= \frac{1}{\pi} \frac{d\theta}{dx}
$$
$$
= \frac{1}{\pi} \frac{d}{dx} \arctan \left( \frac{x-\alpha}{\beta} \right)
$$
\begin{equation}
\therefore Pr(x) = \frac{1}{\pi} \left( \frac{\beta}{\beta^2 + (x-\alpha)^2} \right)
\label{eq:pdf_x}
\end{equation}

Where the last line follows from the standard derivative formula for the arctan function:
\[
\frac{d}{dx} \arctan(x) = \frac{1}{1+x^2}
\]
Using this expression with the chain rule, we obtain the probability density function for \( x \) as shown.

\section{Finding the Lighthouse}
\subsection{Part iii - Most likely location of a flash}
Given the previously calculated probability density function of \( x \), the distribution can be visualised for different light house locations. Figure \ref{fig:cauchy_distribution} shows the probability density function of \( x \) for 3 different choices of \( \alpha \) and \( \beta \). The plots reveal several interesting properties about the PDF of $x$. Firstly, as the value of $\beta$ decreases, the peak
becomes more pronounced. This makes sense as, the closer the lighthouse to the shore, the more information its flashes would give about its location along the shore. The plots also reveals that the peak of the distribution occurs at $x=\alpha$, this can also be seen by inspection of equation \ref{eq:pdf_x}. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/cauchy_distribution.png}
    \caption{Probability density function of \( x \) for 3 different choices of \( \alpha \) and \( \beta \)}
    \label{fig:cauchy_distribution}
\end{figure}

To estimate $\alpha$, one may consider using the sample mean of $x$, however, since $x$ follows a cauchy distribution, the sample mean will not converge as the distribution's mean and variance are both undefined.

Another way to show that the sample mean is not a good estimator of $\alpha$ is to consider the maximum likelihood estimator of $\alpha$, which is a good estimator.

The MLE estimate of $\alpha$ can be found by taking the derivative of the log likelihood function with respect to $\alpha$ and setting it to zero. The likelihood function of a set of flashes $\{x_k\}$ is given by:
\[
L(\{x_k\}|\alpha,\beta) = \prod_{k=1}^{N} Pr(x_k),
\] this follows by the independence of the flashes. The log likelihood function is then given by:
\[
\log L(\{x_k\}|\alpha,\beta) = \sum_{k=1}^{N} \log Pr(x_k).
\] Substituting in the expression for $Pr(x)$ from equation \ref{eq:pdf_x} gives:
\[
\log L(\{x_k\}|\alpha,\beta) = \sum_{k=1}^{N} \log \left( \frac{\beta}{\pi(\beta^2 + (x_k-\alpha)^2)} \right).
\]
Taking the derivative of this with respect to $\alpha$ and setting it to zero gives the expression:
\[
0 = \sum_{k=1}^{N} \frac{2(x_k-\hat\alpha)}{(\beta^2 + (x_k - \hat\alpha)^2)^2},
\] where $\hat\alpha$ is the MLE estimate of $\alpha$. This equation can be solved numerically to find the MLE estimate of $\alpha$. Note how the MLE estimate of $\alpha$ is not the sample mean of $x$.

\subsection{Part iv - Prior distribution of $\alpha$ and $\beta$}

To build a posterior distribution of $\alpha$ and $\beta$, we need to define a prior distribution for these parameters. The choice of prior should capture the current state of belief regarding the values of $\alpha$ and $\beta$. As the lighthouse is equally likely to be at any location along the coast and at any distance from the coast, choosing a uniform prior distribution is a sensible approach. This is because a uniform prior distribution assigns equal probability to all values of $\alpha$ and $\beta$. 
\begin{equation}
Pr(\alpha, \beta) = \left\{
    \begin{array}{ll}
        \frac{1}{(a-b)(c-d)} & \text{if }  a \leq \alpha \leq b \text{ and } c \leq \beta \leq d  \\
        0 & \text{otherwise}
    \end{array}
\right.
\end{equation}

In theory the values for $a$, $b$, $c$ and $d$ should be determined in a manner which does not involve the data. However, in practice, to ensure the prior provides relevant support, the values of $a$, $b$, $c$ and $d$ are set by looking at the data and deciding on a conservative range. In this case, the values of $a$, $b$, $c$ and $d$ were set to be $-100$, $100$, $0$, $100$ respectively.


\subsection{Part v - Posterior distribution of $\alpha$ and $\beta$}

The posterior $p(\alpha, \beta | \{x_k\})$ can be found using Bayes' theorem:
\[
p(\alpha, \beta | \{x_k\}) = \frac{p(\{x_k\} | \alpha, \beta) p(\alpha, \beta)}{p(\{x_k\})},
\] where $p(\{x_k\} | \alpha, \beta)$ is the likelihood function, $p(\alpha, \beta)$ is the prior distribution and $p(\{x_k\})$ is the bayesian evidence. 
% Explain MH algorithm.
To draw samples from the posterior distribution, we can use the Metropolis-Hastings algorithm. The Metropolis-Hastings algorithm is a Markov Chain Monte Carlo (MCMC)
method that generates a sequence of samples from a target distribution. The algorithm works by first proposing a distribution $Q$ and starting point $\mathbf{x_0}$. The proposal is selected to be a distribution which is easy to sample from. Points are drawn from this proposal distribution and accepted or rejected based on an acceptance ratio. The acceptance ratio is a function of the proposal distribution and the target distribution. In the case below, a 2 dimensional gaussian is used as the proposal to draw points $(\alpha, \beta)$.
% Explain pros and cons of MH algorithm
This sampling algorithm is simple and also convenient in that it works only using ratios of the target distribution so the evidence is not required. The algorithm is outlined in Algorithm \ref{alg:metropolis_hastings}.

\begin{algorithm}[H]
    \caption{Metropolis Hastings}
    \begin{algorithmic}[1]
    \State $x_0 \sim \alpha$
    \State $i \gets 0$
    \While{$i \geq 0$}
        \State $y \sim Q(y|x_i)$ \Comment{Proposal}
        \State $a \gets \left(\frac{P(y)Q(x_i|y)}{P(x_i)Q(y|x_i)}\right)$ \Comment{MH acceptance probability}
        \State $u \sim U(0,1)$
        \If{$u < a$}
            \State $x_{i+1} \gets y$ \Comment{Accept}
        \Else
            \State $x_{i+1} \gets x_i$ \Comment{Reject}
        \EndIf
        \State $i \gets i + 1$
    \EndWhile
    \end{algorithmic}
    \label{alg:metropolis_hastings}
\end{algorithm}
    
Note that the expression for the acceptance ratio $a$ simplifies to the ratio of the target distribution $\frac{P(y)}{P(x_i)}$ as the proposal distribution is symmetric. This is a key feature of the Metropolis-Hastings algorithm with symmetric proposal distributions. It is assumed that there is no correlation between the parameters $\alpha$ and $\beta$. As such the covariance matrix for the 2D gaussian proposal distribution is diagonal. 

Since the consecutive points in the chain are generated sequentially from the previous point, they are not independent. To go from the samples returned by the Metropolis-Hastings algorithm to independent samples, there are 2 corrections that are made to the chain. Specifically, the 'burn-in' period must be discarded and the samples must be thinned. 
The burn-in period is the number of samples that are discarded at the start of the chain before it converges towards the target distribution, ensuring that the subsequent samples are not influenced by the choice of initial values. The burn in is normally determined manually be inspecting the trace plots. The trace plot is just the name given to the plot of the random variables values (in this case $\alpha$ and $\beta$) as the chain progresses. 
The thinning factor is the number of samples that are skipped to reduce the correlation between samples. To determine the number of samples to skip, the integrated autocorrelation time (IAT) is calculated. 
\subsubsection{Aside: Emcee integrated autocorrelation time}
To compute IAT, the \texttt{emcee.autocorr.integrate\_time} function was used. 
This package deviates slightly from the definition of IAT. Which is defined as:
\begin{equation}
\tau_f = \sum_{\tau=-\infty}^{\infty} \rho_f(\tau)
\end{equation}
where  \(\tau_f\) is the IAT, \(\tau\) is the lag, which is the distance between elements of the chain, \(\rho_f(\tau)\) is the normalised autocorrelation as a function of \(\tau\). For a finite chain, you can estimate \(\rho_f(\tau)\) as
\begin{equation}
\hat{\rho}_f(\tau) = \frac{\hat{c}_f(\tau)}{\hat{c}_f(0)}
\end{equation}
where
\begin{equation}
\hat{c}_f(\tau) = \frac{1}{N - \tau} \sum_{n=1}^{N-\tau} (f_n - \mu_f) (f_{n+\tau} - \mu_f)
\end{equation}
and
\begin{equation}
\mu_f = \frac{1}{N} \sum_{n=1}^{N} f_n.
\end{equation}
Here \(N\) is the length of the chain and \(f_n\) is the value of the chain at the \(n\)th step and \(\mu_f\) is the sample mean of the chain. The integrated autocorrelation time \(\tau_f\) can now be estimated as:

\begin{equation}
\hat{\tau}_f = \sum_{\tau=-(N-1)}^{N-1} \hat{\rho}_f(\tau) = 1 + 2 \sum_{\tau=1}^{N-1} \hat{\rho}_f(\tau)
\end{equation}
However, the \texttt{emcee} package uses the following estimator for \(\tau_f\). 
\begin{equation}
\hat{\tau}_f(M) = 1 + 2 \sum_{\tau=1}^{M} \hat{\rho}_f(\tau)
\end{equation}
For some \(M \ll N\).  choosing the smallest value of \(M\) where \(M \ge C \hat{\tau}_f(M)\) for a constant \(C \approx 5\). This approach decreases the variance of the estimator at the cost of bias. A more detailed discussion can be found.

% Show param tuning of MH algorithm - justify 0 correlation between alpha and beta,
\subsubsection{Tuning the proposal distribution}
To optimise the standard deviation for the proposal distribution in an MCMC simulation, the following procedure was adopted:
\begin{enumerate}
    \item A range of variances was selected for examination.
    \item For each variance, 10 short MCMC chains were initiated, with starting points sampled from a uniform prior distribution.
    \item The average integrated autocorrelation time (IAT) for each chain was calculated.
    \item The variance leading to the lowest average IAT was identified as optimal.
    \item The same standard deviation was used for both parameters $\alpha$ and $\beta$ to reduce the search space.
\end{enumerate}

This approach determined that the optimal variance for the proposal distribution is 1. Figure \ref{fig:std_tuning} shows the IAT for different variances. Additionally, figure \ref{fig:std_tuning} also shows the acceptance rate for each variance. However, it is important to note that the acceptance rate does not contribute additional information into selecting the optimal variance. This is because the the metropolis hasting algorithm involves retaining rejected points in the chain. The acceptance rate is shown purely for completeness.



% Plot of auto corr vs std size and efficiency vs std size
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/autocorrelation_time_vs_var.png}
    \caption{Acceptance rate and integrated autocorrelation time for different standard deviations}
    \label{fig:std_tuning}
\end{figure}

% Show joint hist, marginals and mean +- std of alpha and beta
\subsubsection{Sampling the posterior distribution}
10 chains were run for 100000 samples each. The burn in period was set to 10000, which is a very conservative estimate according to the trace plots shown in figures \ref{fig:trace_plots_alpha_1} and \ref{fig:trace_plots_beta_1} and the thinning factor was set using twice the maximum auto correlation length between alpha and beta for each chain after discarding the burn-in. The samples were then plotted as a joint histogram as shown in figure \ref{fig:joint_hist_1}. The marginal histograms are shown in figure \ref{fig:marginal_hist} and the mean and standard deviation of the samples are shown in table \ref{tab:mean_std}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/joint_hist_1.png}
    \caption{Joint histogram of samples of $\alpha$ and $\beta$}
    \label{fig:joint_hist_1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/marginals_1.png}
    \caption{Marginal histograms of samples of $\alpha$ and $\beta$}
    \label{fig:marginal_hist}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Parameter & Mean & Standard Deviation \\ \midrule
    $\alpha$  & -0.449 & 0.6028 \\
    $\beta$   & 1.969 & 0.6673 \\ \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of samples of $\alpha$ and $\beta$}
    \label{tab:mean_std}
\end{table}

\subsubsection{Convergence diagnostics}
To ensure that the chains have converged, the trace plots of the chains shown in figures \ref{fig:trace_plots_alpha_1} and \ref{fig:trace_plots_beta_1} were inspected. The plots show that after the burn in period, the chains are well mixed and do not show any non stationary behaviour. These are signs of convergence.

Another criteria used to assess the convergence was the gelman rubin statistic which compares the variance within each chain to the variance across the chains. The idea is that if all chains are converging to the same distribution, the within-chain variance should be similar to the between-chain variance. The statistics were calculated to be 1.0003 and 1.0001 for $\alpha$ and $\beta$ respectively, indicative of convergence.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_alpha_1.png}
    \caption{Trace plots of samples of $\alpha$}
    \label{fig:trace_plots_alpha_1}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/trace_plot_beta_1.png}
    \caption{Trace plots of samples of $\beta$}
    \label{fig:trace_plots_beta_1}
\end{figure}
\section{Introducing Intensity - $I$}
The analysis is repeated now using the additional intensity measurements $I_k$ for $k = 1, 2, \ldots, N$ collected by the detectors. Intensity measurements are assumed to be independant and follow a log-normal distribution with an uncertainty of 1. The likelihood function for a single flashes intensity is given by:
\begin{equation}
    L(I|\alpha,\beta, I_0, x) = \frac{1}{I\sqrt{2\pi}} \exp\left(-\frac{1}{2} \left( \log(I) - \mu\right)^2 \right),
    \label{eq:likelihood_intensity}
\end{equation}
where $\mu = \log(I_0) - 2\log{\left(\beta^2+(x-\alpha^2)\right)}$.

\subsection{Part vi - Prior distribution of $I_0$}
The log uniform distribution was chosen as the prior distribution for the new parameter $I_0$. This is because it respects the scale invariant property of the parameter. It assigns equal probability to all orders of magnitude of $I_0$. The log-uniform prior is defined as:

\begin{equation}
    Pr(I_0) = \left\{
        \begin{array}{ll}
            \frac{1}{I_0(\log(b/a))} & \text{if } a \leq I_0 \leq b \\
            0 & \text{otherwise}
        \end{array}
    \right.
\end{equation}

\subsubsection{Aside: Scale invariance of the log-uniform prior}
A distribution $Pr(x)$ is said to be scale invariant if it satisfies the following condition:
$$
Pr(x)dx = Pr(\alpha x) d(\alpha x),
$$ where $\alpha$ is some positive constant. This is equivalent to saying:
$$
\frac{Pr(x)}{Pr(\alpha x)} = \alpha
$$
If $Pr(x)$ is a log-uniform distribution, then:
$$
Pr(x) = \frac{1}{x(\log(b/a))}
$$
$$
Pr(\alpha x) = \frac{1}{\alpha x(\log(b/a))}
$$
$$
\frac{Pr(x)}{Pr(\alpha x)} = \frac{\alpha x(\log(b/a))}{x(\log(b/a))} = \alpha
$$
Therefore, the log-uniform distribution is scale invariant.

\subsection{Posterior distribution of $\alpha$, $\beta$ and $I_0$}

 The posterior distribution of $\alpha$, $\beta$ and $I_0$ can be found using Bayes' theorem:
\begin{equation}
    Pr(\alpha, \beta, I_0 | \{x_k, I_k\}) = \frac{Pr(\{x_k, I_k\} | \alpha, \beta, I_0) Pr(\alpha, \beta, I_0)}{Pr(\{x_k, I_k\})},
\end{equation}
Applying the independance to factorise the likelihoods of the intensity measurements and the position measurements gives the following expression for the posterior:
$$
Pr(\alpha, \beta, I_0 | \{x_k, I_k\}) = \frac{Pr(\{I_k\} | \alpha, \beta, I_0,\{x_k\})Pr(\{x_k\} | \alpha, \beta)  Pr(\alpha, \beta)Pr(I_0)}{Pr(\{x_k\})Pr(\{I_k\})},
$$


\subsection{Tuning the proposal distribution}
Before drawing samples from the posterior, the covariance matrix for the proposal distribution was tuned. It was found through some experimentation that the IAT was most sensitive to the variance of the $\beta$ and $I_0$ parameters. These were swept over using a single chain with 20000 elements which started in a region of high probability $x_0 = (0, 1, 1)$. The results are shown in figure \ref{fig:std_tuning_2}. The optimal variance was found to be 1 for $\alpha$, 0.1 for $\beta$ and 5 for $I_0$.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/IAT_heatmap.png}
    \caption{Integrated autocorrelation time for different $\beta$ and $I_0$ variances of the proposal distribution}
    \label{fig:std_tuning_2}
\end{figure}
\subsection{Part vii - Drawing stochastic samples from the Posterior of $\alpha$, $\beta$ and $I\_0$}
To draw samples from the posterior, 10 chains were run with taking 100000 steps each. The burn in period for each chain was set to 10000 and the thinning factor was set to twice the maximum IAT between $\alpha$, $\beta$ and $I_0$ for each chain. The samples were then used to generate the corner plot shown in figure \ref{fig:corner_plot}. The mean and standard deviation of the marginal distributions for each parameter are shown in table \ref{tab:mean_std_2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figs/corner_plot_2.png}
    \caption{Corner plot of samples $\alpha$, $\beta$ and $I_0$ from the posterior distribution.}
    \label{fig:corner_plot}
\end{figure}

\begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    Parameter & Mean & Standard Deviation \\ \midrule
    $\alpha$  & -0.201 & 0.3290 \\
    $\beta$   & 1.513 & 0.3646 \\
    $I_0$    & 3.749 & 1.232 \\ \bottomrule
    \end{tabular}
    \caption{Mean and standard deviation of the parameter's $\alpha$, $\beta$ and $I_0$ marginal distributions.}
    \label{tab:mean_std_2}
\end{table}

\bibliographystyle{plainnat} % or another style depending on your requirements
\bibliography{ref.bib} % the name of your .bib file

% % Think about the best 
% \end{document}

\end{document}